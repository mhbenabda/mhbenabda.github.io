<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Deep Learning Reconstruction of Optoacoustic images on FPGA | Habib Ben Abda </title> <meta name="author" content="Habib Ben Abda"> <meta name="description" content="Deep Learning on AMD Kria™ K26 SOM optimized for the DPU"> <meta name="keywords" content="Habib, Mohamed Habib Ben Abda, Ben Abda"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png8?7e21635e694143db903949b9fedeadc0"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mhbenabda.github.io/projects/4_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Habib</span> Ben Abda </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Portfolio <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deep Learning Reconstruction of Optoacoustic images on FPGA</h1> <p class="post-description">Deep Learning on AMD Kria™ K26 SOM optimized for the DPU</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_thumbnail-480.webp 480w,/assets/img/p4_thumbnail-800.webp 800w,/assets/img/p4_thumbnail-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_thumbnail.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Autoencoder running on KRIA K26 for reconstruction of optoacoustic imaging signal. </div> <h2 id="overview">Overview</h2> <p>The standard reconstruction of optoacoustic images (similar to ultrasound) is <strong>Delay and Sum</strong>, an inverse problem that requires high computational load for high-resolution imaging. While advanced imaging became possible over the last 20 years thanks to increased computational power, Delay &amp; Sum is surprisingly inefficient on GPUs. This stems from non-trivial indexing and irregular memory access patterns caused by the data dependencies involved in this method—each pixel requires signals from many sensors.</p> <p>My goal is to develop a real-time image reconstruction using deep learning, optimized for today’s AI accelerators.</p> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_delay-480.webp 480w,/assets/img/p4_delay-800.webp 800w,/assets/img/p4_delay-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_delay.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_delay" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> </div> <h2 id="optoacoustic">Optoacoustic</h2> <p>Optoacoustic imaging is similar to ultrasound, but instead of sending and receiving a pressure wave, we create one by focusing a laser pulse at a specific point. This causes thermal expansion, generating a pressure wave that travels back to be received by piezoelectric sensors.</p> <p>This imaging modality is non-ionizing, making it completely safe, and can offer high resolution at both the vascular and molecular level—enabling applications like measuring oxygen levels and detecting early-stage cancer.</p> <div class="row justify-content-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_opto-480.webp 480w,/assets/img/p4_opto-800.webp 800w,/assets/img/p4_opto-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_opto.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_opto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> </div> <h2 id="dataset">Dataset</h2> <p>The data was collected at Professor Daniel Razansky’s Lab with recordings from human right and left arms. In total, I worked with around 5,500 float32 images. They were recorded using a multisegment array—as shown in the figure below—with a linear section and two arch sections, totaling 256 channels.</p> <div class="row justify-content-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_data-480.webp 480w,/assets/img/p4_data-800.webp 800w,/assets/img/p4_data-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_data.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_data" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Dataset </div> <h2 id="target-device">Target Device</h2> <p>I used the Kria K260 Robotics Kit to deploy the model and run the inference. This is a System On Module (SOM) from AMD dedicated to high-performance and intelligent industrial applications. Its most attractive feature is the <strong>Deep Learning Processing Unit</strong> (DPU), which enables real-time imaging. The DPU is essentially a microcoded compute engine with an optimized instruction set for machine learning operations, especially convolutions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_target-480.webp 480w,/assets/img/p4_target-800.webp 800w,/assets/img/p4_target-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_target.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_target" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Processing Unit of The Kria K26 SOM </div> <h2 id="model-design-and-deployment">Model Design and Deployment</h2> <ul> <li> <strong>Model Selection:</strong> Currently, the best network architectures for biomedical image segmentation and reconstruction are U-Net autoencoders. I chose this because it’s fast, precise, and CNN-based, which is optimal for the DPU.</li> <li> <strong>Preprocessing:</strong> First, to generate my ground truth images, I used standard delay and sum and normalized the images. For my time series pressure signal input, I started with <strong>DC offset removal</strong>, then applied <strong>median padding</strong> to resize images from (256×1006) to (256×1024) for power-of-2 compatibility, followed by <strong>normalizing</strong> to zero mean and unit variance, and finally removing outliers caused by bad recordings.</li> <li> <strong>Hardware Adaptation:</strong> The key challenge here was ensuring all inference operations ran on the DPU rather than being offloaded to the CPU. This meant using only DPU-supported operations—specific kernel sizes, no adaptive pooling, no resizing, no custom functions, etc.</li> <li> <strong>Training and Deployment:</strong> Training was done offline using PyTorch. The final model was then transformed into ONNX format and quantized to INT8 using Vitis AI, then compiled to create a deployable .xmodel file, which is essentially a mapping of the neural network to the specific hardware architecture. Vitis AI is the IDE for deploying pretrained models quickly on AMD platforms and accelerating inference on the DPU without working on bare metal.</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_unet256-480.webp 480w,/assets/img/p4_unet256-800.webp 800w,/assets/img/p4_unet256-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_unet256%0A%20%20%20%20%20%20%20%20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_unet256" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Processing Unit of The Kria K26 SOM </div> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_flow-480.webp 480w,/assets/img/p4_flow-800.webp 800w,/assets/img/p4_flow-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_flow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_flow" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Development Flow </div> <h2 id="results">Results</h2> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p4_result-480.webp 480w,/assets/img/p4_result-800.webp 800w,/assets/img/p4_result-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/p4_result.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p4_result" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example Output </div> <p>As shown in the figure above, the reconstruction on the test set successfully exposed the main features of the image. We can see the main reflecting line in the middle and the arches on the bottom of the picture. The model evaluation resulted in:</p> <ul> <li>Mean Square Error (MSE): 0.567</li> <li>Parameter Size: 7.5 MB (much smaller than the 4 GB DDR4 memory)</li> <li>Inference time: due to time constraints, I didn’t evaluate it on the Kria; however, on my laptop I was able to reach 6 fps, which is already promising—it will definitely achieve real-time performance on the DPU.</li> </ul> <p>Finally, I also explored sub-channel sampling using only the signal from the linear segment for reconstruction, which resulted in a smaller model (about half the size) but naturally slightly worse image quality with an MSE of 0.7.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Habib Ben Abda. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>